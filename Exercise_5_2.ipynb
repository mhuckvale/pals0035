{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_5_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuckvale/pals0039/blob/master/Exercise_5_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWoJVUEQQNBT"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "# Exercise 5.2\n",
        "\n",
        "In this exercise we use an implementation of the Word2Vec model to build our own word embeddings for a (relatively) small dataset.\n",
        "\n",
        "Adapted from [https://blog.cambridgespark.com/tutorial-build-your-own-embedding-and-use-it-in-a-neural-network](https://blog.cambridgespark.com/tutorial-build-your-own-embedding-and-use-it-in-a-neural-network-e9cde4a81296)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlIL6nylWm6s"
      },
      "source": [
        "(a) Get the Brown Corpus. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAmnl9NDQJmh"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# \n",
        "import nltk\n",
        "\n",
        "# \n",
        "nltk.download('brown')\n",
        "\n",
        "# \n",
        "from nltk.corpus import brown\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W77xGgZWWvOm"
      },
      "source": [
        "---\n",
        "(b) Get tokenized sentences from Brown. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUdWUy1cQk0L"
      },
      "source": [
        "# \n",
        "sentences=brown.sents()\n",
        "print(len(sentences))\n",
        "\n",
        "# \n",
        "for sent in sentences[:5]:\n",
        "  print(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKz62r0xW1k1"
      },
      "source": [
        "---\n",
        "(c) Get the optimised Word2vec training code from gensim [https://radimrehurek.com/gensim/models/word2vec.html](https://radimrehurek.com/gensim/models/word2vec.html). Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om6qvQ4QQ8vR"
      },
      "source": [
        "# the gensim models are already available in Colab\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# \n",
        "print(dir(Word2Vec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ACl6M57XC5W"
      },
      "source": [
        "---\n",
        "(d) Train the Word2Vec model (takes about a minute with GPU). Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0hlWrabRLEi"
      },
      "source": [
        "# special command in Colab to keep track of execution time. Try with and without GPU.\n",
        "%%time\n",
        "\n",
        "# \n",
        "EMB_DIM=100\n",
        "\n",
        "# \n",
        "model=Word2Vec(sentences,size=EMB_DIM,window=5,min_count=5,negative=15,iter=5,sg=1)\n",
        "\n",
        "# \n",
        "word_vectors=model.wv\n",
        "\n",
        "# \n",
        "print(\"Vocab size\", len(word_vectors.vocab.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU9QdLEzXI0c"
      },
      "source": [
        "---\n",
        "(e) Look up some similarities. Run the code and add comments. Then try out some different example words.\n",
        "\n",
        "You might compare the results here with the lecture Demo that uses pre-trained GloVe embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSfQ6Wd-SFO9"
      },
      "source": [
        "# \n",
        "result=word_vectors.similar_by_word('Saturday')\n",
        "print(\"Saturday:\",result[:5])\n",
        "result=word_vectors.similar_by_word('money')\n",
        "print(\"Money:\",result[:5])\n",
        "result=word_vectors.similar_by_word('child')\n",
        "print(\"Child:\",result[:5])\n",
        "\n",
        "# \n",
        "result=word_vectors.most_similar(positive=['play'],negative=['expensive'])\n",
        "print(\"play-expensive:\",result[:5])\n",
        "\n",
        "# \n",
        "result=word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(\"woman+king-man:\",result)\n",
        "\n",
        "# \n",
        "result=word_vectors.doesnt_match(\"breakfast cereal dinner lunch\".split())\n",
        "print(\"Does not match:\",result)\n",
        "\n",
        "# \n",
        "result=word_vectors.similarity('woman', 'man')\n",
        "print(\"Woman:Man \",result)\n",
        "\n",
        "# \n",
        "result=word_vectors['computer']\n",
        "print(\"Computer:\",result)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}