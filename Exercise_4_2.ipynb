{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_4_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuckvale/pals0039/blob/master/Exercise_4_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba_u4lIeY3lI"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "#Exercise 4.2\n",
        "\n",
        "In this exercise we implement a DNN for recognition of emotion from speech.\n",
        "\n",
        "The data comes from recordings made at the [Enterface05 summer school](http://www.enterface.net/).\n",
        "\n",
        "The audio recordings have been extracted from the video files, and each has been processed through the [OpenSMILE](https://www.audeering.com/opensmile/) feature extractor. Each recording is represented by a fixed-length vector of 6373 features. Every recording also has an emotion label from the set <tt>['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']</tt> which was the target emotion given to each speaker. The code loads the data from a CSV file, encodes the emotion classes as numbers, the selects random subsets for training and testing. We then build a DNN classifier and display its performance as a confusion matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr7p4QeSY3zH"
      },
      "source": [
        "---\r\n",
        "(a) Set-up. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3zsmTrycoqU"
      },
      "source": [
        "# \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# \n",
        "%tensorflow_version 2.x\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEvOtgoFcvtL"
      },
      "source": [
        "---\n",
        "(b) Download the data set and measure its parameters. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMMVpaDcculb"
      },
      "source": [
        "# \n",
        "df=pd.read_csv(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/emotion.csv\",sep=',')\n",
        "\n",
        "#\n",
        "print(\"Number of rows=\",len(df))\n",
        "print(\"Number of columns=\",len(df.columns))\n",
        "\n",
        "# \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql_VI2a5du-E"
      },
      "source": [
        "---\n",
        "(c) Convert data and labels into numpy arrays. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0VXwrrDd0yN"
      },
      "source": [
        "# \n",
        "df['EMOTION']=pd.Categorical(df['EMOTION'])\n",
        "\n",
        "# \n",
        "emolist=list(df['EMOTION'].cat.categories)\n",
        "print(emolist)\n",
        "\n",
        "# \n",
        "Xdata=np.array(df.iloc[:,4:])\n",
        "ydata=np.array(df['EMOTION'].cat.codes)\n",
        "\n",
        "# \n",
        "ndata=Xdata.shape[0]\n",
        "# \n",
        "p=np.random.permutation(ndata)\n",
        "#\n",
        "ntrain=int(0.9*ndata)\n",
        "\n",
        "# \n",
        "Xtrain=Xdata[p[:ntrain],:]\n",
        "Xtest=Xdata[p[ntrain:],:]\n",
        "ytrain=ydata[p[:ntrain]]\n",
        "ytest=ydata[p[ntrain:]]\n",
        "\n",
        "print(Xtrain[:10,:20])\n",
        "print(ytrain[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yapUMnnyhqYv"
      },
      "source": [
        "---\n",
        "(d) Build the DNN model. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dar4sx0Thvap"
      },
      "source": [
        "# \n",
        "isize=Xtrain.shape[1];\n",
        "osize=len(emolist)\n",
        "print(\"inputs\",isize,\"outputs\",osize)\n",
        "\n",
        "# \n",
        "model = Sequential()\n",
        "# \n",
        "model.add(Dense(64,activation='tanh',input_shape=(isize,)))\n",
        "# \n",
        "model.add(Dense(16,activation='tanh'));\n",
        "# \n",
        "model.add(Dense(osize, activation='softmax'))\n",
        "# \n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F17DebXPieNj"
      },
      "source": [
        "---\n",
        "(e) Train the model. Run the code and add comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8IIHPEsiiUi"
      },
      "source": [
        "# \n",
        "history=model.fit(Xtrain,ytrain, epochs=10, batch_size=64, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0SPdgeji-E7"
      },
      "source": [
        "---\n",
        "(f) Evaluate the model on the test data. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGgikOsBi9Cb"
      },
      "source": [
        "# \n",
        "loss,accuracy=model.evaluate(Xtest,ytest)\n",
        "print(\"Loss\",loss,\"Accuracy\",accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRVl6cJTjOhi"
      },
      "source": [
        "---\n",
        "(g) Print confusion matrix. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxAFzNMqjWUT"
      },
      "source": [
        "#\n",
        "ypred=model.predict(Xtest)\n",
        "\n",
        "#\n",
        "ypred=np.argmax(ypred,axis=1)\n",
        "\n",
        "# \n",
        "counts=np.zeros((osize,osize))\n",
        "correct=0\n",
        "# \n",
        "for i in range(len(ytest)):\n",
        "  if (ypred[i]==ytest[i]):\n",
        "    correct += 1\n",
        "  counts[ytest[i],ypred[i]] += 1\n",
        "\n",
        "# \n",
        "print(emolist)\n",
        "print(counts)\n",
        "print(\"Correct %.1f%%\" % (100*correct/len(ytest)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dip-6Zkc9Zu"
      },
      "source": [
        "---\r\n",
        "(h) Experiment with the example to try and improve performance. Here are some ideas:\r\n",
        "<ol>\r\n",
        "<li>Change the size and structure of the network.\r\n",
        "<li>Change the training regime.\r\n",
        "<li>(advanced) Select a subset of the 6373 features according to how much they vary between emotion classes in the training set. Eliminate the unused features (those that don't vary much across classes) from both training and testing data.\r\n",
        "</ol>"
      ]
    }
  ]
}