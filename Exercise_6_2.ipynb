{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_6_2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuckvale/pals0039/blob/master/Exercise_6_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDf62qJtHhGd",
        "colab_type": "text"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "# Exercise 6.2\n",
        "\n",
        "In this exercise we build a small vocabulary isolated word recogniser using a recurrent network classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WHH4jo7Hl5j",
        "colab_type": "text"
      },
      "source": [
        "(a) Import the usual libraries. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW0GPt89Hgi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# \n",
        "%tensorflow_version 2.x\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, SimpleRNN, LSTM, GRU, Bidirectional, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7a1rGfzHwkc",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(b) Download a data set and prepare for processing. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6VF8X01H7ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "COMMANDS={ \"yes\":0, \"no\":1, \"up\":2, \"down\":3, \"left\":4, \"right\":5, \"on\":6, \"off\":7, \"stop\":8, \"go\":9 }\n",
        "\n",
        "# \n",
        "def prepare_data(filename,maxseq):\n",
        "  # \n",
        "  df=pd.read_csv(filename)\n",
        "  # \n",
        "  grouped=df.groupby(\"FILE\")\n",
        "  nseq=len(grouped)\n",
        "  # \n",
        "  feats=np.zeros((nseq,maxseq,19))\n",
        "  # \n",
        "  labels=np.zeros((nseq),dtype='int')\n",
        "  # \n",
        "  i=0\n",
        "  for name,group in grouped:\n",
        "    # \n",
        "    n=min(len(group),maxseq)\n",
        "    # \n",
        "    feats[i,0:n,:] = group.iloc[0:n,2:21].to_numpy()\n",
        "    # \n",
        "    labels[i]=COMMANDS[group.LABEL.iat[0]]\n",
        "    i+=1\n",
        "  \n",
        "  # \n",
        "  limit=np.amax(feats)-50\n",
        "  feats=(feats-limit)/50\n",
        "  feats[feats<0]=0\n",
        "  \n",
        "  p = np.random.permutation(nseq)\n",
        "  return feats[p,:,:],labels[p]\n",
        "\n",
        "# \n",
        "Xtrain, ytrain = prepare_data(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/command-train.csv\",100)\n",
        "Xval, yval = prepare_data(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/command-valid.csv\",100)\n",
        "Xtest, ytest = prepare_data(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/command-test.csv\",100)\n",
        "\n",
        "# \n",
        "print(Xtrain.shape,ytrain.shape)\n",
        "print(Xval.shape,yval.shape)\n",
        "print(Xtest.shape,ytest.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ag34RPW5Ng6",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(c) Display some of the command words. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoQaKcp65RhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "labellist=list(COMMANDS.keys())\n",
        "# \n",
        "for i in range(5):\n",
        "  # \n",
        "  word = Xtrain[i]\n",
        "  plt.imshow(word.T, origin='lower',cmap='binary')\n",
        "  # \n",
        "  plt.title(labellist[int(ytrain[i])])\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFPNr1h6rJ0O",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(d) Build a model. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9CrBaskrNFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "seqlen=Xtrain.shape[1]\n",
        "isize=Xtrain.shape[2]\n",
        "osize=len(COMMANDS)\n",
        "\n",
        "# \n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(16, return_sequences=True),merge_mode='ave',input_shape=(seqlen,isize)));\n",
        "model.add(Flatten())\n",
        "model.add(Dense(osize, activation='softmax'));\n",
        "#\n",
        "# \n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-VawdMdrWGJ",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(e) Train the model. Run the code and add commants."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbtOM6J9rbdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "history=model.fit(Xtrain,ytrain, validation_data=(Xval,yval), epochs=25)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P2rSJ5QrcT1",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(f) Evaluate model on test set. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHNu1H2NrfIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "score,acc = model.evaluate(Xtest,ytest,verbose=0)\n",
        "print(\"Test accuracy: %.2f\" % (acc));\n",
        "\n",
        "# \n",
        "ypred = model.predict(Xtest)\n",
        "ypred=np.argmax(ypred,axis=1)\n",
        "\n",
        "# \n",
        "labellist=COMMANDS.keys()\n",
        "\n",
        "# \n",
        "y_actu = pd.Categorical.from_codes(ytest, categories=labellist)\n",
        "y_pred = pd.Categorical.from_codes(ypred, categories=labellist)\n",
        "df_confusion = pd.crosstab(y_actu, y_pred, margins=False, normalize='index',dropna=False)\n",
        "df_confusion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7QTHfcqH1N-",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(g) Experiment with different network configurations and amounts of training. Plot the loss and accuracy curves for the train and validation data. What is the best performance you can obtain on the test set?"
      ]
    }
  ]
}