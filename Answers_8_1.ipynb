{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Answers_8_1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuckvale/pals0039/blob/master/Answers_8_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsuMCkqDNArY",
        "colab_type": "text"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "# Exercise 8.1 Answers\n",
        "\n",
        "In this exercise we use a seq2seq model to address the problem of grapheme to phoneme conversion. We use an English pronunciation dictionary called BEEP which has been converted to the SAMPA machine readable prounciation format. This exercise draws on the Keras example for seq2seq processing: [https://keras.io/examples/lstm_seq2seq/](https://keras.io/examples/lstm_seq2seq/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFuZqgM5IPD0",
        "colab_type": "text"
      },
      "source": [
        "(a) Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f2ZGjXiIHPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRysYfVPIhM8",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(b) Load the pronunciation dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0h0NxZCIizk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url=\"https://www.phon.ucl.ac.uk/courses/pals0039/data/english-dictionary.csv\"\n",
        "\n",
        "df=pd.read_csv(url,keep_default_na=False)\n",
        "print(df.head())\n",
        "print(df.tail())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y6rx4SnOjjC",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(c) Build the input and output vocabulary of symbols. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1LIqtgMOyve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get list of all characters used in ortography\n",
        "inputs=df.INPUT.to_list()\n",
        "input_chars=sorted(list(set(\"\".join(inputs))))\n",
        "# add space as a special character\n",
        "input_chars.append(' ')\n",
        "print(input_chars)\n",
        "# get list of all the characters used in transcription\n",
        "targets=df.TARGET.to_list()\n",
        "target_chars=sorted(list(set(\"\".join(targets))))\n",
        "# add space and square brackets as special characters\n",
        "target_chars.append('[')\n",
        "target_chars.append(']')\n",
        "target_chars.append(' ')\n",
        "print(target_chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYwZ6YZggp1p",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(d) Get basic parameters for learning. Run the code and add comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcpqs_PqgtFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of pronunciations\n",
        "num_samples=len(df)\n",
        "# number of different tokens used in orthography\n",
        "num_encoder_tokens = len(input_chars)\n",
        "# number of differet tokens used in transcription\n",
        "num_decoder_tokens = len(target_chars)\n",
        "# maximum lengths of words and pronunciations\n",
        "max_encoder_seq_length = max([len(txt) for txt in df.INPUT.to_list()])\n",
        "max_decoder_seq_length = max([len(txt) for txt in df.TARGET.to_list()])+2   # plus 2 for BOS=[ and EOS=]\n",
        "\n",
        "print('Number of samples:', num_samples)\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "\n",
        "# build dictionaries for letters and phones\n",
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_chars)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_chars)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_5Uoo-hj3yF",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(e) Build training data. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfmrCLpCj6l9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list of sequences to be used for encoder input\n",
        "encoder_input_data = np.zeros((num_samples, max_encoder_seq_length, num_encoder_tokens),dtype='float32')\n",
        "# list of sequences to be used for decoder input (= target shifted right one place)\n",
        "decoder_input_data = np.zeros((num_samples, max_decoder_seq_length, num_decoder_tokens),dtype='float32')\n",
        "# list of sequences to be used for decoder output\n",
        "decoder_target_data = np.zeros((num_samples, max_decoder_seq_length, num_decoder_tokens),dtype='float32')\n",
        "\n",
        "# encode orthogaphy as sequence of one-hot vectors\n",
        "def encode_str(str):\n",
        "  input_text=str.ljust(max_encoder_seq_length)\n",
        "  data=np.zeros((max_encoder_seq_length,num_encoder_tokens))\n",
        "  for t, char in enumerate(input_text):\n",
        "    data[t, input_token_index[char]] = 1.\n",
        "  return data\n",
        "\n",
        "# encode all pronunciations as sequences of one-hot vectors\n",
        "for i in range(num_samples):\n",
        "  encoder_input_data[i,:,:]=encode_str(df.INPUT.at[i])\n",
        "  target_text=(\"[\"+df.TARGET.at[i]+\"]\").ljust(max_decoder_seq_length)\n",
        "  for t, char in enumerate(target_text):\n",
        "    # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "    decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "    if t > 0:\n",
        "      # decoder_target_data will be ahead by one timestep\n",
        "      # and will not include the start character.\n",
        "      decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "\n",
        "# random shuffle\n",
        "nseq=encoder_input_data.shape[0]\n",
        "p = np.random.permutation(nseq)\n",
        "encoder_input_data = encoder_input_data[p]\n",
        "decoder_input_data = decoder_input_data[p]\n",
        "decoder_target_data = decoder_target_data[p]\n",
        "\n",
        "print(encoder_input_data.shape,decoder_input_data.shape,decoder_target_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKgWFBu5n1eD",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(f) Build the seq2seq model for training. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjir9alan-OC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Latent dimensionality of the encoding space.\n",
        "latent_dim = 256  \n",
        "\n",
        "# Define the input sequence and process it through LSTMs to get encoder state at end\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSQV97IAodLJ",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(g) Train the seq2seq encoder. Training takes about 5 minutes. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtderxQyoe6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 5  # Number of epochs to train for.\n",
        "batch_size = 64  # Batch size for training.\n",
        "\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.05)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk0fHgSgo0AR",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(h) Build inference model. Run the code and add comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfcI9aFNo39p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next: inference mode (sampling).\n",
        "# 1) encode input and retrieve initial decoder state\n",
        "# 2) run one step of decoder with this initial state and a \"start of sequence\" token as input.\n",
        "# Output will be the next target token\n",
        "# 3) Repeat with this target as input and the current state passed forward\n",
        "\n",
        "# Define sampling model\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "# take state from encoder\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "# decoder LSTM takes decoder state and decoder input to produce one new output\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "  # reshape the input into a single row tensor\n",
        "  input_tensor=np.reshape(input_seq,(1,input_seq.shape[0],input_seq.shape[1]))\n",
        "  # Encode the input as state vectors.\n",
        "  states_value = encoder_model.predict(input_tensor)\n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "  # Populate the first character of target sequence with the start character.\n",
        "  target_seq[0, 0, target_token_index['[']] = 1.\n",
        "\n",
        "  # Sampling loop for a batch of sequences\n",
        "  # (to simplify, here we assume a batch of size 1).\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "    # Sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "\n",
        "    # Exit condition: either hit max length\n",
        "    # or find stop character.\n",
        "    if (sampled_char == ']' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "      stop_condition = True\n",
        "    else:\n",
        "      decoded_sentence += sampled_char\n",
        "\n",
        "    # Update the target sequence (of length 1).\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "    # Update states\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLA6BUdSpkVj",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(i) Try out model with some samples. Think of some words to test the pronunciation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR4LdI8NpoDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "examples=[ \"england\", \"wales\", \"scotland\", \"oxford\", \"greenhouse\"]\n",
        "for ex in examples:\n",
        "  data=encode_str(ex.upper())\n",
        "  decoded=decode_sequence(data)\n",
        "  print('-')\n",
        "  print('Input:', ex)\n",
        "  print('Pronunciation:', decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuOrp1T_2Pl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while True:\n",
        "  ex=input(\"Type word (q to quit): \")\n",
        "  if ex==\"q\":\n",
        "    break\n",
        "  data=encode_str(ex.upper())\n",
        "  decoded=decode_sequence(data)\n",
        "  print('Input:', ex)\n",
        "  print('Pronunciation:', decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}