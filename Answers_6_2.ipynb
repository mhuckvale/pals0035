{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Answers_6_2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuckvale/pals0039/blob/master/Answers_6_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDf62qJtHhGd",
        "colab_type": "text"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "# Exercise 6.2 Answers\n",
        "\n",
        "In this exercise we build a small vocabulary isolated word recogniser using a recurrent network classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WHH4jo7Hl5j",
        "colab_type": "text"
      },
      "source": [
        "(a) Import the usual libraries. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW0GPt89Hgi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import standard library modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# import keras toolkit\n",
        "%tensorflow_version 2.x\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, SimpleRNN, LSTM, GRU, Bidirectional, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7a1rGfzHwkc",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(b) Download a data set and prepare for processing. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6VF8X01H7ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up the coding we will use for the commands as a dictionary\n",
        "COMMANDS={ \"yes\":0, \"no\":1, \"up\":2, \"down\":3, \"left\":4, \"right\":5, \"on\":6, \"off\":7, \"stop\":8, \"go\":9 }\n",
        "\n",
        "# download the speech data and unpack into contant length sequences\n",
        "def prepare_data(filename,maxseq):\n",
        "  # read the dataset\n",
        "  df=pd.read_csv(filename)\n",
        "  # group the data by recording\n",
        "  grouped=df.groupby(\"FILE\")\n",
        "  nseq=len(grouped)\n",
        "  # set up the array to hold the feature date (19=#filterbankchannels)\n",
        "  feats=np.zeros((nseq,maxseq,19))\n",
        "  # set up the array to hold the command codes\n",
        "  labels=np.zeros((nseq),dtype='int')\n",
        "  # loop through each group (=each file)\n",
        "  i=0\n",
        "  for name,group in grouped:\n",
        "    # name = command name, group=speech data\n",
        "    n=min(len(group),maxseq)\n",
        "    # copy the speech data into the feature array\n",
        "    feats[i,0:n,:] = group.iloc[0:n,2:21].to_numpy()\n",
        "    # copy the command name into the labels array\n",
        "    labels[i]=COMMANDS[group.LABEL.iat[0]]\n",
        "    i+=1\n",
        "  # normalise the data so that the top 50dB is mapped to 0..1\n",
        "  limit=np.amax(feats)-50\n",
        "  feats=(feats-limit)/50\n",
        "  feats[feats<0]=0\n",
        "  # return the imported data in random order\n",
        "  p = np.random.permutation(nseq)\n",
        "  return feats[p,:,:],labels[p]\n",
        "\n",
        "# load training, validation and test data\n",
        "Xtrain, ytrain = prepare_data(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/command-train.csv\",100)\n",
        "Xval, yval = prepare_data(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/command-valid.csv\",100)\n",
        "Xtest, ytest = prepare_data(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/command-test.csv\",100)\n",
        "\n",
        "# report what we have got\n",
        "print(Xtrain.shape,ytrain.shape)\n",
        "print(Xval.shape,yval.shape)\n",
        "print(Xtest.shape,ytest.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ag34RPW5Ng6",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(c) Display some of the command words. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoQaKcp65RhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get list of command words\n",
        "labellist=list(COMMANDS.keys())\n",
        "# for the first five words\n",
        "for i in range(5):\n",
        "  # display the spectrogram\n",
        "  word = Xtrain[i]\n",
        "  plt.imshow(word.T, origin='lower',cmap='binary')\n",
        "  # title with the name of command\n",
        "  plt.title(labellist[int(ytrain[i])])\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFPNr1h6rJ0O",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(d) Build a model. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9CrBaskrNFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get basic sizes of problem\n",
        "seqlen=Xtrain.shape[1]\n",
        "isize=Xtrain.shape[2]\n",
        "osize=len(COMMANDS)\n",
        "\n",
        "# build a recurrent network with 10 outputs\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(16, return_sequences=True),merge_mode='ave',input_shape=(seqlen,isize)));\n",
        "model.add(Flatten())\n",
        "model.add(Dense(osize, activation='softmax'));\n",
        "#\n",
        "# compile the network to produce 10-way classifications specified as integer labels\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-VawdMdrWGJ",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(e) Train the model. Run the code and add commants."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbtOM6J9rbdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model for 25 epochs (may not be enough)\n",
        "history=model.fit(Xtrain,ytrain, validation_data=(Xval,yval), epochs=25)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P2rSJ5QrcT1",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(f) Evaluate model on test set. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHNu1H2NrfIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the accuracy on the test data\n",
        "score,acc = model.evaluate(Xtest,ytest,verbose=0)\n",
        "print(\"Test accuracy: %.2f\" % (acc));\n",
        "\n",
        "# get the actual predictions\n",
        "ypred = model.predict(Xtest)\n",
        "ypred=np.argmax(ypred,axis=1)\n",
        "\n",
        "# get the list of commands\n",
        "labellist=COMMANDS.keys()\n",
        "\n",
        "# use the pandas crosstabs function to calculate and print confusion matrix\n",
        "y_actu = pd.Categorical.from_codes(ytest, categories=labellist)\n",
        "y_pred = pd.Categorical.from_codes(ypred, categories=labellist)\n",
        "df_confusion = pd.crosstab(y_actu, y_pred, margins=False, normalize='index',dropna=False)\n",
        "df_confusion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7QTHfcqH1N-",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(g) Experiment with different network configurations and amounts of training. Plot the loss and accuracy curves for the train and validation data. What is the best performance you can obtain on the test set?"
      ]
    }
  ]
}