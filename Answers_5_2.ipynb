{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Answers_5_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuckvale/pals0039/blob/master/Answers_5_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWoJVUEQQNBT"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "# Exercise 5.2 Answers\n",
        "\n",
        "In this exercise we use an implementation of the Word2Vec model to build our own word embeddings for a (relatively) small dataset.\n",
        "\n",
        "Adapted from [https://blog.cambridgespark.com/tutorial-build-your-own-embedding-and-use-it-in-a-neural-network](https://blog.cambridgespark.com/tutorial-build-your-own-embedding-and-use-it-in-a-neural-network-e9cde4a81296)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlIL6nylWm6s"
      },
      "source": [
        "(a) Get the Brown Corpus. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAmnl9NDQJmh"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# import the NLTK toolkit\n",
        "import nltk\n",
        "\n",
        "# download the Brown corpus\n",
        "nltk.download('brown')\n",
        "\n",
        "# read in the Brown corpus object\n",
        "from nltk.corpus import brown\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W77xGgZWWvOm"
      },
      "source": [
        "---\n",
        "(b) Get tokenized sentences from Brown. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUdWUy1cQk0L"
      },
      "source": [
        "# get the corpus as word lists, one list per sentence\n",
        "sentences=brown.sents()\n",
        "print(len(sentences))\n",
        "\n",
        "# print the first few sentences\n",
        "for sent in sentences[:5]:\n",
        "  print(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKz62r0xW1k1"
      },
      "source": [
        "---\n",
        "(c) Get the optimised Word2vec training code from gensim [https://radimrehurek.com/gensim/models/word2vec.html](https://radimrehurek.com/gensim/models/word2vec.html). Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om6qvQ4QQ8vR"
      },
      "source": [
        "# the gensim models are already available in Colab\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# print available methods\n",
        "print(dir(Word2Vec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ACl6M57XC5W"
      },
      "source": [
        "---\n",
        "(d) Train the Word2Vec model (takes about a minute with GPU). Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0hlWrabRLEi"
      },
      "source": [
        "# special command in Colab to keep track of execution time. Try with and without GPU.\n",
        "%%time\n",
        "\n",
        "# choose embedding size\n",
        "EMB_DIM=100\n",
        "\n",
        "# train the embedding\n",
        "model=Word2Vec(sentences,size=EMB_DIM,window=5,min_count=5,negative=15,iter=5,sg=1)\n",
        "\n",
        "# get the word vectors\n",
        "word_vectors=model.wv\n",
        "\n",
        "# report the vocabulary size\n",
        "print(\"Vocab size\", len(word_vectors.vocab.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU9QdLEzXI0c"
      },
      "source": [
        "---\n",
        "(e) Look up some similarities. Run the code and add comments. Then try out some different example words.\n",
        "\n",
        "You might compare the results here with the lecture Demo that uses pre-trained GloVe embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSfQ6Wd-SFO9"
      },
      "source": [
        "# find words similar to a given word\n",
        "result=word_vectors.similar_by_word('Saturday')\n",
        "print(\"Saturday:\",result[:5])\n",
        "result=word_vectors.similar_by_word('money')\n",
        "print(\"Money:\",result[:5])\n",
        "result=word_vectors.similar_by_word('child')\n",
        "print(\"Child:\",result[:5])\n",
        "\n",
        "# find word that means cheap idea for play\n",
        "result=word_vectors.most_similar(positive=['play'],negative=['expensive'])\n",
        "print(\"play-expensive:\",result[:5])\n",
        "\n",
        "# find word that means female king\n",
        "result=word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(\"woman+king-man:\",result)\n",
        "\n",
        "# find word which does not match the others\n",
        "result=word_vectors.doesnt_match(\"breakfast cereal dinner lunch\".split())\n",
        "print(\"Does not match:\",result)\n",
        "\n",
        "# get numerical similarity of two words\n",
        "result=word_vectors.similarity('woman', 'man')\n",
        "print(\"Woman:Man \",result)\n",
        "\n",
        "# report the whole vector for a word\n",
        "result=word_vectors['computer']\n",
        "print(\"Computer:\",result)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}