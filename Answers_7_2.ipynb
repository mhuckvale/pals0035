{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Answers_7_2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuckvale/pals0039/blob/master/Answers_7_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7KKVn4ADsTj",
        "colab_type": "text"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "# Exercise 7.2 Answers\n",
        "\n",
        "In this exercise we build a word language model using a recurrent network. We test it on a Cloze task in which we have to choose which word fits best within a given sentence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAGoWqZaDuLi",
        "colab_type": "text"
      },
      "source": [
        "(a) Setup libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK3T32_LDmD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, SimpleRNN, LSTM, GRU, Bidirectional, Dropout, TimeDistributed\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import get_file\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_JMdV-wDzaD",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(b) Load the text we will use for training. This is a collection of stories from the Gutenberg archive. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWFm0EEpD2W7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download the training text\n",
        "url = \"https://www.phon.ucl.ac.uk/courses/pals0039/data/cloze-corpus.txt\"\n",
        "response = requests.get(url)\n",
        "# convert the text to a single lower case string\n",
        "raw_text = response.text.lower().replace('\\n',' ')\n",
        "print(\"Corpus has\",len(raw_text),\"characters\")\n",
        "print(raw_text[:250])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxz2xmaREHuz",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(c) Tokenize the text. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la_koZiXESba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the vocabulary limit to be 10,000 words\n",
        "max_words=10000\n",
        "\n",
        "# use the Keras Tokenizer\n",
        "tokenizer = Tokenizer(num_words=max_words,oov_token=\"UNK\")\n",
        "tokenizer.fit_on_texts([raw_text])\n",
        "word_index=tokenizer.word_index\n",
        "print(\"Found\",len(word_index),\"different words.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouxB9goEFqaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the 10 most common and 10 least common words\n",
        "print(list(word_index.items())[:10])\n",
        "print(list(word_index.items())[-10:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XK6h7FyGyMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the text to a list of word indexes, replacing rare words with UNK\n",
        "raw_seq=tokenizer.texts_to_sequences([raw_text])[0]\n",
        "# print the start of the sample\n",
        "print(raw_seq[:50])\n",
        "# report largest code\n",
        "print(\"# words\",len(raw_seq),\"Max index\",max(raw_seq))\n",
        "# calculate the out-of-vocabulary rate\n",
        "num_oov=sum(1 for w in raw_seq if w==1)\n",
        "print(\"%OOV\",100*num_oov/len(raw_seq))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a8iMhEgJJST",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(d) Prepare the text sample for training. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVk3QwLrJLiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# divide the text into sequences of fixed length\n",
        "seq_len=100\n",
        "nseq=len(raw_seq)//seq_len\n",
        "# chunk the text into sequences\n",
        "seq=np.reshape(raw_seq[:nseq*seq_len],(nseq,seq_len))\n",
        "# shift the text back one word\n",
        "raw_seq_shift=np.roll(raw_seq,-1) \n",
        "# and chunk into sequences to act as targets\n",
        "seq_shift=np.reshape(raw_seq_shift[:nseq*seq_len],(nseq,seq_len))\n",
        "# randomise the order of the sequences\n",
        "p = np.random.permutation(nseq)\n",
        "seq=seq[p]\n",
        "seq_shift=seq_shift[p];\n",
        "\n",
        "# divide into train and validation sets\n",
        "nval=nseq//10\n",
        "Xval=seq[:nval,:]\n",
        "yval=seq_shift[:nval,:]\n",
        "Xtrain=seq[nval:,:]\n",
        "ytrain=seq_shift[nval:,:]\n",
        "\n",
        "print(Xtrain.shape,ytrain.shape)\n",
        "print(Xval.shape,yval.shape)\n",
        "\n",
        "print(Xtrain[0,:10],ytrain[0,:10])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIc0HRVTI2cu",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(e) Build a recurrent model. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXfWunrUI5R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "# define a function for Keras to report perplexity during training\n",
        "def perplexity(y_true, y_pred):\n",
        "    cross_entropy = tf.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "    perplexity = tf.exp(tf.reduce_mean(cross_entropy))\n",
        "    return perplexity\n",
        "\n",
        "# set up basic sizes for nextwork\n",
        "isize=max_words\n",
        "embed_size=64\n",
        "osize=max_words\n",
        "\n",
        "# build the model with an embedding layer and two layers of LSTMs\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=isize, output_dim=embed_size,input_length=seq_len))\n",
        "model.add(LSTM(32,return_sequences=True,activation='tanh'))\n",
        "model.add(LSTM(32,return_sequences=True,activation='tanh'))\n",
        "model.add(TimeDistributed(Dense(osize, activation='softmax')));\n",
        "#\n",
        "# compile the network\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=[perplexity])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxlpOwNCMjUU",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(f) Train the model. Experiment with different network configurations and training protocol. There is also code here to save and restore trained models since training can take some time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9R6egn-Mk9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "history=model.fit(Xtrain,ytrain, batch_size=64, validation_data=(Xval,yval), epochs=25)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8M1XwKoRhm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (optional) save the model to your Google drive account\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "model_save_name = 'ex72.h5'\n",
        "path = \"/content/gdrive/My Drive/\"+model_save_name\n",
        "model.save(path,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4EBOPi7TKih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (optional) load a trained model from your Google drive account\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "model_save_name = 'ex72.h5'\n",
        "path = \"/content/gdrive/My Drive/\"+model_save_name\n",
        "model=load_model(path, custom_objects={'perplexity': perplexity})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4il7VQlTmoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (optional) load a trained model from the course website\n",
        "model_save_name = 'ex72.h5'\n",
        "url = \"https://www.phon.ucl.ac.uk/courses/pals0039/data/\"+model_save_name\n",
        "file = get_file(model_save_name,url,cache_subdir=\"models\")\n",
        "model=load_model(file, custom_objects={'perplexity': perplexity})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVJIa66JVuLA",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(g) Load the data for cloze task to use for testing. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgt_wesuBIGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read in the Cloze data set from the course web site.\n",
        "df=pd.read_csv(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/cloze-test.csv\",keep_default_na=False)\n",
        "\n",
        "# the basics of the Cloze task is made up of the columns: df.CONTEXT, df.QUERY and df.ALTERNATIVES with the correct answer in df.ANSWER\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttBq6-LvY9EX",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(h) Encode the cloze test data using the tokenizer and assemble into sequences. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdVmtbtUZjm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenate the context and the query and divide up the alternatives\n",
        "cloze_context=[]\n",
        "cloze_answer=[]\n",
        "cloze_alter=[]\n",
        "for i in range(len(df)):\n",
        "  # concatenate the CONTEXT and the QUERY to get sufficient text for the LM\n",
        "  str=df.CONTEXT.iat[i]+\" \"+df.CONTEXT.iat[i]+\" \"+df.QUERY.iat[i]\n",
        "  cloze_context.append(str)\n",
        "  cloze_answer.append(df.ANSWER.iat[i])\n",
        "  cloze_alter.append((df.ALTERNATIVES.iat[i]).split('|'))\n",
        "\n",
        "# convert the strings to integer sequences\n",
        "cloze_context_seq=tokenizer.texts_to_sequences(cloze_context)\n",
        "cloze_answer_seq=tokenizer.texts_to_sequences(cloze_answer)\n",
        "cloze_alter_seq=tokenizer.texts_to_sequences(cloze_alter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv7WufBtbmtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print some samples of what we have\n",
        "print(cloze_context[0])\n",
        "print(cloze_context_seq[0])\n",
        "print(cloze_answer[:10])\n",
        "print(cloze_answer_seq[:10])\n",
        "print(cloze_alter[:10])\n",
        "print(cloze_alter_seq[:10])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNYhwMwMb_xk",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(i) Run the model over the all the test sequences and obtain a pdf over the word that completes the query. Run the code and add comments. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr7fn3tXcGtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len=100\n",
        "# chop all context sequences down to seq_len values by taking the last 100 words\n",
        "cloze_context_lim=np.stack(np.array([ x[-seq_len:] for x in cloze_context_seq]))\n",
        "print(cloze_context_lim.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0de5QDqAawi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run the model in batches of 100 so as not to overload memory\n",
        "block_size=50\n",
        "nblock=cloze_context_lim.shape[0]//block_size\n",
        "# array to hold the word probabilities\n",
        "ypred=np.zeros((nblock*block_size,max_words))\n",
        "for i in range(nblock):\n",
        "  # get the predicted word probabilities\n",
        "  testdata=cloze_context_lim[i*block_size:(i+1)*block_size,:]\n",
        "  pred=model.predict(testdata,batch_size=50)\n",
        "  # save the probabilities for the last predicted word\n",
        "  ypred[i*block_size:(i+1)*block_size,:]=pred[:,-1,:]\n",
        "\n",
        "print(ypred.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT5RBA8vVaQK",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(j) For each cloze sentence, find the probabilities of each of the alternatives and choose the most probable. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyjxZfMjFBDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for each cloze sentence in turn\n",
        "ntest=ypred.shape[0]\n",
        "ncorrect=0;\n",
        "for i in range(ntest):\n",
        "  # get the number of alternatives\n",
        "  nprob=len(cloze_alter_seq[i])\n",
        "  # get the predicted probabilities\n",
        "  prob=np.zeros(nprob)\n",
        "  for j in range(nprob):\n",
        "    prob[j]=ypred[i,cloze_alter_seq[i][j]]\n",
        "  # choose the most probable among the alternatives\n",
        "  top_word=cloze_alter_seq[i][np.argmax(prob)]\n",
        "  # get the actually correct word\n",
        "  correct_word=cloze_answer_seq[i][0]\n",
        "  # record whether we got it right\n",
        "  if (top_word==correct_word):\n",
        "    ncorrect += 1\n",
        "\n",
        "# print how well we did\n",
        "print(\"Correct: %d/%d (%.1f%%)\" % (ncorrect,ntest,100*ncorrect/ntest))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}