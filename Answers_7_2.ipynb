{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Answers_7_2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuckvale/pals0039/blob/master/Answers_7_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7KKVn4ADsTj",
        "colab_type": "text"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "# Exercise 7.2 Answers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAGoWqZaDuLi",
        "colab_type": "text"
      },
      "source": [
        "(a) Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK3T32_LDmD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, SimpleRNN, LSTM, GRU, Bidirectional, Dropout, TimeDistributed\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import get_file\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_JMdV-wDzaD",
        "colab_type": "text"
      },
      "source": [
        "(b) load text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWFm0EEpD2W7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.phon.ucl.ac.uk/courses/pals0039/data/cloze-corpus.txt\"\n",
        "response = requests.get(url)\n",
        "raw_text = response.text.lower().replace('\\n',' ')\n",
        "print(\"Corpus has\",len(raw_text),\"characters\")\n",
        "print(raw_text[:250])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxz2xmaREHuz",
        "colab_type": "text"
      },
      "source": [
        "(c) Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la_koZiXESba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words=10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words,oov_token=\"UNK\")\n",
        "tokenizer.fit_on_texts([raw_text])\n",
        "word_index=tokenizer.word_index\n",
        "print(\"Found\",len(word_index),\"different words.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouxB9goEFqaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(list(word_index.items())[:10])\n",
        "print(list(word_index.items())[-10:])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XK6h7FyGyMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_seq=tokenizer.texts_to_sequences([raw_text])[0]\n",
        "print(raw_seq[:100])\n",
        "print(\"Max index\",max(raw_seq))\n",
        "num_oov=sum(1 for w in raw_seq if w==1)\n",
        "print(\"%OOV\",100*num_oov/len(raw_seq))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a8iMhEgJJST",
        "colab_type": "text"
      },
      "source": [
        "(d) prepare for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVk3QwLrJLiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len=100\n",
        "nseq=len(raw_seq)//seq_len\n",
        "seq=np.reshape(raw_seq[:nseq*seq_len],(nseq,seq_len))   # convert to list of sequences\n",
        "seq_shift=np.roll(seq,-1)     # target is sequence shifted back one step\n",
        "p = np.random.permutation(nseq)\n",
        "seq=seq[p]\n",
        "seq_shift=seq_shift[p];\n",
        "\n",
        "nval=nseq//10\n",
        "\n",
        "Xval=seq[:nval,:]\n",
        "yval=seq_shift[:nval,:]\n",
        "Xtrain=seq[nval:,:]\n",
        "ytrain=seq_shift[nval:,:]\n",
        "\n",
        "print(Xtrain.shape,ytrain.shape)\n",
        "print(Xval.shape,yval.shape)\n",
        "\n",
        "print(Xtrain[0,:10],ytrain[0,:10])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIc0HRVTI2cu",
        "colab_type": "text"
      },
      "source": [
        "(e) build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXfWunrUI5R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "def perplexity(y_true, y_pred):\n",
        "    cross_entropy = tf.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "    perplexity = tf.exp(tf.reduce_mean(cross_entropy))\n",
        "    return perplexity\n",
        "\n",
        "osize=max_words\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=64,input_length=seq_len))\n",
        "model.add(LSTM(256,return_sequences=True,activation='tanh'))\n",
        "model.add(LSTM(256,return_sequences=True,activation='tanh'))\n",
        "model.add(TimeDistributed(Dense(osize, activation='softmax')));\n",
        "#\n",
        "# compile the network\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=[perplexity])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxlpOwNCMjUU",
        "colab_type": "text"
      },
      "source": [
        "(f) train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9R6egn-Mk9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "history=model.fit(Xtrain,ytrain, batch_size=64, validation_data=(Xval,yval), epochs=25)\n",
        "#print(history.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8M1XwKoRhm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "model_save_name = 'ex72.h5'\n",
        "path = \"/content/gdrive/My Drive/\"+model_save_name\n",
        "model.save(path,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVJIa66JVuLA",
        "colab_type": "text"
      },
      "source": [
        "(g) load test data for cloze task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl862Pv6Vx12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "model_save_name = 'ex72.h5'\n",
        "path = \"/content/gdrive/My Drive/\"+model_save_name\n",
        "model=load_model(path, custom_objects={'perplexity': perplexity})\n",
        "\n",
        "#url = \"https://www.phon.ucl.ac.uk/courses/pals0039/data/\"+model_save_name\n",
        "#file = get_file(model_save_name,url,cache_subdir=\"models\")\n",
        "#model=load_model(file, custom_objects={'perplexity': perplexity})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgt_wesuBIGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/cloze-test.csv\",keep_default_na=False)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttBq6-LvY9EX",
        "colab_type": "text"
      },
      "source": [
        "(h) encode the cloze test data using the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdVmtbtUZjm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenate the context and the query\n",
        "cloze_context=[]\n",
        "cloze_answer=[]\n",
        "cloze_alter=[]\n",
        "for i in range(len(df)):\n",
        "  str=df.CONTEXT.iat[i]+\" \"+df.CONTEXT.iat[i]+\" \"+df.QUERY.iat[i]\n",
        "  cloze_context.append(str)\n",
        "  cloze_answer.append(df.ANSWER.iat[i])\n",
        "  cloze_alter.append((df.ALTERNATIVES.iat[i]).split('|'))\n",
        "\n",
        "cloze_context_seq=tokenizer.texts_to_sequences(cloze_context)\n",
        "cloze_answer_seq=tokenizer.texts_to_sequences(cloze_answer)\n",
        "cloze_alter_seq=tokenizer.texts_to_sequences(cloze_alter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv7WufBtbmtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(cloze_context[0])\n",
        "print(cloze_context_seq[0])\n",
        "print(cloze_answer[:10])\n",
        "print(cloze_answer_seq[:10])\n",
        "print(cloze_alter[:10])\n",
        "print(cloze_alter_seq[:10])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNYhwMwMb_xk",
        "colab_type": "text"
      },
      "source": [
        "(i) run the model over the sequences to get pdf over next word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr7fn3tXcGtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(seq_len)\n",
        "seq_len=100\n",
        "# chop all lists down to seq_len values\n",
        "print(cloze_context_seq[:5])\n",
        "x=cloze_context_seq[0]\n",
        "print(x)\n",
        "print(x[-seq_len:])\n",
        "lengths=[ len(x) for x in cloze_context_seq]\n",
        "print(min(lengths),max(lengths))\n",
        "cloze_context_lim=np.stack(np.array([ x[-seq_len:] for x in cloze_context_seq]))\n",
        "print(cloze_context_lim[0])\n",
        "print(cloze_context_lim[1])\n",
        "print(cloze_context_lim.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0de5QDqAawi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "block_size=100\n",
        "nblock=cloze_context_lim.shape[0]//block_size\n",
        "ypred=np.zeros((nblock*block_size,max_words))\n",
        "for i in range(nblock):\n",
        "  pred=model.predict(cloze_context_lim[i*block_size:(i+1)*block_size,:],batch_size=50)\n",
        "  ypred[i*block_size:(i+1)*block_size,:]=pred[:,-1,:]   # just pdf of last word of each sentence\n",
        "print(ypred.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyjxZfMjFBDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find alternative with highest probability\n",
        "ntest=ypred.shape[0]\n",
        "ncorrect=0;\n",
        "for i in range(ntest):\n",
        "  nprob=len(cloze_alter_seq[i])\n",
        "  prob=np.zeros(nprob)\n",
        "  for j in range(nprob):\n",
        "    prob[j]=ypred[i,cloze_alter_seq[i][j]]\n",
        "  top_word=cloze_alter_seq[i][np.argmax(prob)]\n",
        "  correct_word=cloze_answer_seq[i][0]\n",
        "  if (top_word==correct_word):\n",
        "    ncorrect += 1\n",
        "  #print(i,correct_word,top_word,ncorrect)\n",
        "\n",
        "print(\"Correct: %d/%d (%.1f%%)\" % (ncorrect,ntest,100*ncorrect/ntest))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-StK1fBl0aJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}