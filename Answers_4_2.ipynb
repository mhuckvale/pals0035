{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Answers_4_2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuckvale/pals0039/blob/master/Answers_4_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba_u4lIeY3lI",
        "colab_type": "text"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "#Exercise 4.2 Answers\n",
        "\n",
        "In this exercise we implement a DNN for recognition of emotion from speech.\n",
        "\n",
        "The data comes from recordings made at the [Enterface05 summer school](http://www.enterface.net/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr7p4QeSY3zH",
        "colab_type": "text"
      },
      "source": [
        "(a) Set-up. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3zsmTrycoqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import standard libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import Keras library\n",
        "%tensorflow_version 2.x\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEvOtgoFcvtL",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(b) Download the data set and measure its parameters. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMMVpaDcculb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# down load the emotion corpus spreadsheet\n",
        "df=pd.read_csv(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/emotion.csv\",sep=',')\n",
        "\n",
        "# print size\n",
        "print(\"Number of rows=\",len(df))\n",
        "print(\"Number of columns=\",len(df.columns))\n",
        "\n",
        "# print first rows\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql_VI2a5du-E",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(c) Convert into numpy arrays. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0VXwrrDd0yN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the EMOTION column to numbers\n",
        "df['EMOTION']=pd.Categorical(df['EMOTION'])\n",
        "\n",
        "# get a list of the named categories\n",
        "emolist=list(df['EMOTION'].cat.categories)\n",
        "print(emolist)\n",
        "\n",
        "# convert data frame to numpy arrays - selecting training features\n",
        "Xdata=np.array(df.iloc[:,4:])\n",
        "ydata=np.array(df['EMOTION'].cat.codes)\n",
        "\n",
        "# get total number of rows\n",
        "ndata=Xdata.shape[0]\n",
        "# get random order\n",
        "p=np.random.permutation(ndata)\n",
        "# train on 90%\n",
        "ntrain=int(0.9*ndata)\n",
        "\n",
        "# divide into training and test data\n",
        "Xtrain=Xdata[p[:ntrain],:]\n",
        "Xtest=Xdata[p[ntrain:],:]\n",
        "ytrain=ydata[p[:ntrain]]\n",
        "ytest=ydata[p[ntrain:]]\n",
        "\n",
        "print(Xtrain[:10,:20])\n",
        "print(ytrain[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yapUMnnyhqYv",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(d) build DNN model. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dar4sx0Thvap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get some basic sizes of inputs and outputs\n",
        "isize=Xtrain.shape[1];\n",
        "osize=len(emolist)\n",
        "print(\"inputs\",isize,\"outputs\",osize)\n",
        "\n",
        "# use Keras sequentioal model\n",
        "model = Sequential()\n",
        "# add dense layer with isize inputs\n",
        "model.add(Dense(64,activation='tanh',input_shape=(isize,)))\n",
        "# add a hidden layer\n",
        "model.add(Dense(16,activation='tanh'));\n",
        "# add the output layer as set of class probabilities\n",
        "model.add(Dense(osize, activation='softmax'))\n",
        "# compile model using the sparse cross-entropy, which allows us to present the classes as integers\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F17DebXPieNj",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(e) Train the model. Run the code and add comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8IIHPEsiiUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model, using 10% as validation data\n",
        "history=model.fit(Xtrain,ytrain, epochs=10, batch_size=64, validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0SPdgeji-E7",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(f) Evaluate the model on the test data. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGgikOsBi9Cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate the model\n",
        "loss,accuracy=model.evaluate(Xtest,ytest)\n",
        "print(\"Loss\",loss,\"Accuracy\",accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRVl6cJTjOhi",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "(g) Print confusion matrix. Run the code and add comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxAFzNMqjWUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get predictions of the model\n",
        "ypred=model.predict(Xtest)\n",
        "# use argmax to choose most probable\n",
        "ypred=np.argmax(ypred,axis=1)\n",
        "\n",
        "# set up confusion matrix\n",
        "counts=np.zeros((osize,osize))\n",
        "correct=0\n",
        "# compare predictions with correct answer\n",
        "for i in range(len(ytest)):\n",
        "  if (ypred[i]==ytest[i]):\n",
        "    correct += 1\n",
        "  counts[ytest[i],ypred[i]] += 1\n",
        "\n",
        "# print the confusions\n",
        "print(emolist)\n",
        "print(counts)\n",
        "print(\"Correct %.1f%%\" % (100*correct/len(ytest)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}